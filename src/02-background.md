## Background

“An outlier is an observation which deviates so much from other observations as
to arouse suspicions that it was generated by a different mechanism” - Hawkins 1980.

Anomalies often referred to as outliers, abnormalities, rare events or deviants
are data points or patterns in data that do not adhere or conform to a
well-defined notion of normal behavior. Anomaly detection is therefore defined
as the task of finding patterns in data that do not adhere to a well-defined
notion of normal behavior.

The recognition or detection of anomalous behavior provides useful insights. In
fact the applications are so diverse that almost every enterprise has a problem
where it needs to distinguish between what’s normal and what isn’t. Flagging or
having some kind of fallback mechanism in place when these unusual cases occur
can allow them to save time and costs. And hence anomaly detection has found
numerous applications in a variety of domains including financial industry,
fault detection, intrusion detection, web log analytics, social media, and
medical diagnostic use cases. For instance,

With the growth of computer networks usage and the increase in the number of
applications running on top of it, network security is becoming increasingly
more important. All the computer systems suffer from security vulnerabilities
which are both technically difficult and economically costly to be solved by the
manufacturers. These systems collect data about the network traffic, activity in
the system, types of connection requests, etc. This data may provide insights
into unusual activity in the network. Therefore, the role of intrusion detection
systems (IDSs), as special-purpose devices to detect anomalies and attacks in
the network is important.

In many medical diagnosis applications, a variety of data sources like ECG data
that captures the electrical activity of the heart is collected. These
recordings can help cardiologists diagnose heart anomalies and diseases.

In predictive maintenance systems, anomaly detection applications can help
detect an equipment failure in advance.

In the sections below, we discuss a set of known approaches, grouped by how they
model normal behaviour. Given the wide spectrum of problem domains and
techniques the goal of this report is to focus on … set of approaches.

### Learning anomalies

The anomaly detection problem is studied extensively in machine learning and as
a consequence a lot of approaches or techniques have evolved in the past years
(or it encompasses a very broad class of approaches or techniques). To state
broadly, machines learn in three (or four, if you add reinforcement learning)
different ways:

#### Supervised learning

When learning with supervision, machines rely on examples that illustrate the
relationship between the input features and output. The goal of supervised
anomaly detection algorithms is to incorporate application-specific knowledge
into the anomaly detection process. With sufficient normal and anomalous
examples, machines can learn to accurately predict whether a given example is an
anomaly or not given a set of input features. That said, for many anomaly
detection use cases the proportion of normal versus anomalous examples is highly
imbalanced. And while there may be multiple anomalous classes each of them could
be quite under-represented. Plus, when it comes to abnormal examples they are a
lot different from each other and the data available may not represent them all.
Thus, with the rare nature of anomalies, such data is limited and it is hard to
create robust models that can generalize easily.

#### Unsupervised learning

When it comes to unsupervised approaches, one does not possess examples that
illustrate the relationship between input features and output. Instead, in this
case machines learn by finding structure within the input features. Owing to the
lack of labeled anomalous data, unsupervised approaches are more popular than
supervised ones in the anomaly detection field. That said, the nature of the
anomalies is often highly specific to particular kinds of abnormal activity in
the underlying application. In such cases, many of the anomalies found could
correspond to noise, and may not be of any interest to the business.

#### Semi-supervised learning

Semi-supervised learning falls between supervised and unsupervised learning and
leverages unlabeled data for learning along with with the available labeled set.
These approaches are different from (or similar to) supervised learning where
the examples provided for learning belong to only normal class(es) (or only the
abnormal class(es)). Many real world anomaly detection use cases nicely fit this
criteria, in the sense that there are huge number of normal examples available
but the more unusual or abnormal classes of interest are insufficient to be
effectively learned from. In many applications, examples of one or more of
anomalous classes may not even be available.

For instance, in a network intrusion detection application, one may have
examples of the normal class, and some examples of the intrusion classes but new
kinds of intrusions may often arise with time.

<figure here>

To give another example, in the case of border security or X-ray screening for
aviation anomalous items posing a security threat are not commonly encountered.
Exemplary data of such can be difficult to obtain in any quantity since no such
event may have occurred in the first place. In addition, the nature of any
anomaly posing a potential threat may evolve due to a range of external factors.

<figure here>
<can draw ideas from here: https://arxiv.org/pdf/1805.06725.pdf>

Such situations may require the determination of both abnormal classes as well
as novel classes for which no or little labeled data is available. Ofcourse, one
way to deal with this is to use some variant of a supervised classification
approach, but then there are other challenges associated with it.

For one, as mentioned earlier in the “Supervised learning” section it is natural
that the distribution between the normal and abnormal class(es) be very skewed,
commonly referred to as class imbalance. This implies that the model learned
from such data may not be robust in the sense that, it may be very accurate when
it comes to identifying examples with normal class but may suffer disastrously
when it comes to identifying anomalous examples. This means that it may at times
misclassify normal examples as anomalous - false positives. Or even a
less-desirable case where the anomalous examples are classified as normal ones -
false negatives. Depending on the use case/ application, at times higher false
positives could be more desirable than higher false negatives. In other words,
this boils down to the fact that the classification approach has to be modified
to address these challenges of an anomaly detection use case. Note: Here
“modification” means approaches that help deal with class imbalances - modifying
the objective function (cost sensitive learning) or sampling techniques, we
don’t want to go into those explanations.

A related issue is that, in many real world data sources although the normal
examples are easily identifiable, the anomalous ones often more diverse, that
is, they look very different from each other. Consider for example, a scenario
where one would want to classify whether an email is a personal email (non-spam)
or a spam depending on it’s content. In here the concept of "spam" is more
diverse, it could be advertisements for products or web sites, make money fast
schemes, chain letters, pornography, and many others, making it hard to define
what representative anomalous examples are. Whereas a personal email (normal
example) is easily identifiable and available.

Another issue is that anomaly detection applications can often encounter
examples during deployment (or at test time) that are unlike the examples that
have been used during training. For instance, a new kind of attack in a network
intrusion detection application or a novel astronomical phenomenon or a finding
an unknown disease. These situations necessitate us to look into approaches that
can handle novel examples - novelty detection.

While there are ways to address these challenges - better/ modified supervised
approaches to deal with the class imbalance issue, or better data acquisition
with active learning <provide report 10 reference> where one would request
labels for anomalous examples, in general it is hard to obtain a rather large
and diverse representation of the anomalous class(es). Further, each of these
cater to only parts of the overall problem.

##### Learning what normal is

As discussed in the earlier section, sometimes it is easier to obtain normal
data examples rather than anomalous examples. This may be due to numerous
challenges - labeled data availability, diversity and vastness of anomalous
examples, novel anomalous examples at inference, and so on. To some extent, such
situations can be addressed with a combination of supervised and unsupervised
approaches. That said, this is a classic fit for a semi-supervised approach. In
fact, with only normal data available during training, the difference from an
unsupervised approach is that the training data is free of anomalies and the
test data can contain both normal and anomalous samples. Below we discuss some
of the techniques that can be employed in these situations ...

###### One-class SVM

One-class classification approaches trained only on normal data such as
one-class SVMs are widely used; these methods learn a classification boundary
around the normal data and try to determine which examples are similar to the
training data. They learn to model the class present in the training data and
typically use kernel-based transformation along with reference points such as
the origin to determine a synthetic reference point for the other class, so that
the separator can be defined. The choice of reference point does affect the
robustness of the model.

Note: In some papers One-class approaches are not considered as part of
semi-supervised algorithms while in others they are. It seems that they are by
themselves but can also be employed for novelty detection. Novelty detection is
definitely part of the semi-supervised class.

And more .., original paper:
https://papers.nips.cc/paper/1723-support-vector-method-for-novelty-detection.pdf

###### Gaussian Mixture Models

Use of GMMs for one-class classification:
http://vision.cs.tut.fi/data/publications/icpr2006_gaussian.pdf

###### Others?

##### Fidelity of reconstruction

This class of approach uses fidelity of reconstruction to determine whether an
example is anomalous.

###### Principal Component Analysis and its variants

- Robust PCA for Anomaly Detection in Cyber Networks -
  https://arxiv.org/pdf/1801.01571.pdf
- Kernel-based PCA

###### Others?

#### Deep Neural Networks - This should be part of chapter 3

More recent works are based on deep neural networks

Approaches based on autoencoders and variational auto-encoders first train a
model to reconstruct normal data and subsequently identify anomalies as samples
with high reconstruction errors. Finally, GANs have been applied to anomaly
detection in the context of medical imaging on retinal images.

### Building successful anomaly detection applications

- Real-time
- Can scale
- explainable/ interpretable
- reduce FPs
- actionable
- adapts to changes
- timeliness

### What can go wrong?

#### Contaminated normal examples

In large scale applications that have huge volumes of data, it is quite possible
that the large unlabeled data is considered as the normal class wherein a small
percentage of examples may actually be anomalous. The models (one-class SVMs or
isolation forest) should account for this.

#### Computational complexity

Computationally expensive when it comes to generative models (GANs and even
VAEs, etc.) since it requires recovering the latent space at inference time?

#### Human supervision

One major challenge with unsupervised and semi-supervised approaches may not be
very useful. They require human supervision, it is a natural outcome of any
anomaly detection application, since incorporating human feedback allows one to
filter out noisy anomalies.

#### Definition of anomaly evolves with time

The boundary between normal and anomalous behavior is often not precisely
defined in several data domains and is continually evolving.

<NM storyline start>

### Why anomaly detection?

- Gartner insights on anomaly detection costs, lots of examples, news articles -
  Target outages, etc.
- Traditionally people detect unusual situations/ incidents sitting in front of
  dashboards and monitoring them all the time, or create static alerts and if
  its crosses a threshold.
  For instance, alerts when my CPU utilization crosses 95% and such. This tends to
  create a lot of false positives.
  Plus, doesn't scale as well

### Anomaly detection with machine learning

- Why unsupervised approaches? applicable in most real world cases since it's
  hard to get labels. Starting from very basic approaches like 2.5 std devs with
  underlying assumptions, assumes that the time series is stationary, there is no
  seasonality and its a normal distribution!
  These assumptions should eb validated.
- Why not use supervised techniques? labels aren't captured easily. Faulty cases
  differ look a lot different from each other. That is why we would want to
  focus on what normal cases look like and go from there and look for abnomal
  patterns - novelty detection
- how do approaches differ with temporal / time series vs non-temporal data

### Key requirements for successful AD system in enterprises:

- Real-time
- Can scale
- explainable/ interpretable
- reduce FPs
- actionable
- adapts to changes
- timeliness

### Taxonomy of approaches?

statistical, ML, DL
For instance, univariate time series vs multivariate time-series, univariate
techniques are
more easier to explain. At times depending on the use case you may not need to
provide an explanation as well

### Forecasting tied to time-series

### What to consider while building an AD system?

- If you have some known anomalies in the data to help capture review how your
  technique performs
- If there are no labels available whatsoever the only way would to test how
  well it forecasts and how many anomalies it produces
- Off the shelf models, techniques may not work because in real world use cases
  the anomalies are contextual you will have to tune the model or develop a new
  one

<NM storyline end>

### Anomaly Detection - A definition

Anomalies are patterns in data that do not conform to a well-defined notion of normal behavior. Anomaly detection is therefore defined as the task of finding patterns in data that do not conform to a well-defined notion of normal behavior.

To accomplish this task, it is important to first model normal behavior and then exploit this knowledge in the detection of anomalies. While various techniques vary in their approach to each step, they all ultimately follow this general paradigm.

In the sections below, we discuss a set of known approaches, grouped by how they model normal behaviour.

### Distance Based Methods

### One-Class Classification

### Fidelity of Reconstruction

#### Density Estimation

This approach seeks to model the probability distribution of normal data.
A new sample x is listed as an anomaly by estimating its likelihod of being member of the normal data distribution. This process of estimating likelihood usnig sampling can be computationally expensive

#### Prediction

### Challenges of Anomaly Detection

- Anomalies are contextual
  Anomalies are contextual in nature and hence, techniques developed for anomaly detection in one domain can rarely be used ‘as is’ in another domain.

- Anomalies, Uncertainty and Unseen data
  Anomalies can frequently resemble legitimate datapoints.

- Anomalous data is typically scare
  labeled data is typically scarce, making it an unsupervised or semi-supervised problem in most cases.

### Types of Anomaly

- Global or point anomalies
  When the value of an observation falls significantly outside the range of the whole data set. For example a 30°C day on Antarctica.

- Contextual or conditional outliers
  When the value of an observation deviates significantly from the rest of the data set in the same context. The value might however be seen as normal in a different context. Data with seasonal patterns are sensitive to contextual outliers. For example a high level of credit card spending on gifts can be seen as normal in the run up to Christmas but would be a contextual anomaly in mid-January.
- Collective outliers
  When a number of typically sequential observations in a data set deviate significantly from the rest of the data but the individual values of each observation are not seen as an outlier. Figure 1 shows an ECG with a collective outlier (red). While the red values on the ECG are not anomalous on their own, the sequence clearly forms an outlier.

### Anomaly Detection for High Dimension Data: Deep Learning Approaches

#### Why Deep Learning?

##### Dimensionality

Shallow learning or other statistical approaches work well for low dimensional data. However, in the high dimensional data regime, these approaches struggle and thats where deep learning comes in.

###### Tuning

Many existing approaches require mutliple experimentation and tuning of parameters to improve accuracy. For example when using an AR or ARIMA model, parameteres like order, difference, moving average size etc need to be carefully tuned in order to obtain good results. For domains where the notion of of anomaly within data is constantly changing, it can become tedious to repeated tune these parameters.
Deep Learning approaches , if structures correctly can offer some respite from this process by automatically learning its parameters from data.

#### Why Not Deep Learning?

Deep learning approaches can be compute intensive. For high volume real time systems, it can be both prohibitively expensive and slow to apply deep leanring for online AD.
In addition, deep learning models have a significant amount of parameters which need to be trained with a lot of data. Problem spaces with small datastes may not be sutiable to deep learning approaches.

#### Density Estimation

(we learn a distribution of our dataset (x). At test time, given data x, construct measures of how well x fits in our learned distribtuion and flag it as an anomaly based on this assessment)

E.g VAEs, GANs

#### Probability/Predictions

(Given a dataset (x, comprised of a and b) we learn to predict a (a-prime), given b. At test time, given (x, comprised of a and b), if our prediction of a (a-prime), given b is really far from a, we flag this as an anomaly. This approach assumes our underlying prediction model is appropriate and fairly accurate for predicting a.

Point probability approaches
E.g. LSTMs, Seq2Seq Models, Autoencoders, KNNs

### How and When to Apply Deep Learning for Anomaly Detection

While deep learning has shown the best performance for some anomaly detection problems, there are several important considerations that can advise what deep learning approach to consider, if at all.

- Nature of dataset: Is your data labelled? Time Series with temporal relationships?
- Latency: Is your usecase tolerant of high latency?
- Compute Infrastructure: What kind of deployment environment do you currently have or are willing to support. In any case, deep learning approaches work best on GPU hardware.
